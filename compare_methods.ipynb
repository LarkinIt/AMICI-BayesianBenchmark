{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare methods notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import distributions\n",
    "from modelproblem import ModelProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result:\n",
    "\tdef __init__(self, result_dict) -> None:\n",
    "\t\tfor key in result_dict:\n",
    "\t\t\tsetattr(self, key, result_dict[key])\n",
    "\t\tif self.method == \"ptmcmc\":\n",
    "\t\t\tburn_in_idx = self.algo_specific_info[\"burn_in_idx\"]\n",
    "\t\t\tn_chains = self.n_chains\n",
    "\t\t\t#print(f\"{burn_in_idx}, \\t{n_chains}\")\n",
    "\t\t\tself.n_fun_calls = (burn_in_idx+1)*n_chains\n",
    "\n",
    "\tdef get_sampling_ratio(self, par_bounds, par_idx=0) -> float:\n",
    "\t\t\"\"\"\n",
    "\t\tMeasures the ratio of the sampling space \n",
    "\t\texplored for a given parameter index\n",
    "\t\t\"\"\"\n",
    "\t\tbound_diff = par_bounds[par_idx][1] - par_bounds[par_idx][0]\n",
    "\t\tpar_samples = self.all_samples[:, :, par_idx]\n",
    "\t\tmax_val = np.max(par_samples)\n",
    "\t\tmin_val = np.min(par_samples)\n",
    "\t\tsample_diff = max_val - min_val\n",
    "\t\treturn sample_diff/bound_diff\n",
    "\t\n",
    "\tdef get_convergence(self, llh_threshold):\n",
    "\t\tidxs = np.where(self.all_llhs > llh_threshold)\n",
    "\t\tfirst_iter = np.min(idxs[0])\n",
    "\n",
    "\t\tif self.method == \"ptmcmc\":\n",
    "\t\t\t#print(self.all_llhs.shape, self.all_llhs[5:,0], idxs)\n",
    "\t\t\t# ! TO DO: replace this with a more exact calculation\n",
    "\t\t\t#print(first_iter)\n",
    "\t\t\tconv_calls = first_iter * self.n_chains\n",
    "\t\telse:\n",
    "\t\t\tconv_calls = self.algo_specific_info[\"calls_by_iter\"][first_iter]\n",
    "\t\treturn conv_calls\n",
    "\n",
    "class MethodResults:\n",
    "\tdef __init__(self, method) -> None:\n",
    "\t\tself.all_runs = []\n",
    "\t\tself.method = method\n",
    "\t\tif method == \"pmc\":\n",
    "\t\t\tself.abbr = \"PMC\"\n",
    "\t\t\tself.label = \"Preconditioned Monte Carlo\"\n",
    "\t\telif method == \"smc\":\n",
    "\t\t\tself.abbr = \"SMC\"\n",
    "\t\t\tself.label = \"Sequential Monte Carlo\"\n",
    "\t\telif method == \"ptmcmc\":\n",
    "\t\t\tself.abbr = \"PT-MCMC\"\n",
    "\t\t\tself.label = \"Parallel Tempering MCMC\"\n",
    "\t\n",
    "\tdef add_result(self, result_obj):\n",
    "\t\tself.all_runs.append(result_obj)\n",
    "\n",
    "\tdef get_fun_calls(self) -> np.array:\n",
    "\t\tall_calls = [x.n_fun_calls for x in self.all_runs]\n",
    "\t\treturn np.array(all_calls)\n",
    "\t\n",
    "\tdef get_llhs(self) -> np.array:\n",
    "\t\tall_llhs = [x.posterior_llhs for x in self.all_runs]\n",
    "\t\treturn np.array(all_llhs)\n",
    "\t\n",
    "\tdef get_sampling_efficiency(self, bounds, par_idx) -> np.array:\n",
    "\t\tall_ratios = [x.get_sampling_ratio(bounds, par_idx) for x in self.all_runs]\n",
    "\t\treturn np.array(all_ratios)\n",
    "\t\n",
    "\tdef get_convergence_times(self, llh_threshold):\n",
    "\t\tall_convs = [x.get_convergence(llh_threshold) for x in self.all_runs]\n",
    "\t\treturn np.array(all_convs)\n",
    "\t\n",
    "\t# Source: https://stackoverflow.com/questions/40044375/how-to-calculate-the-kolmogorov-smirnov-statistic-between-two-weighted-samples\n",
    "\tdef ks_weighted(self, data1, data2, wei1, wei2, alternative='two-sided'):\n",
    "\t\tix1 = np.argsort(data1)\n",
    "\t\tix2 = np.argsort(data2)\n",
    "\t\tdata1 = data1[ix1]\n",
    "\t\tdata2 = data2[ix2]\n",
    "\t\twei1 = wei1[ix1]\n",
    "\t\twei2 = wei2[ix2]\n",
    "\t\tdata = np.concatenate([data1, data2])\n",
    "\t\tcwei1 = np.hstack([0, np.cumsum(wei1)/sum(wei1)])\n",
    "\t\tcwei2 = np.hstack([0, np.cumsum(wei2)/sum(wei2)])\n",
    "\t\tcdf1we = cwei1[np.searchsorted(data1, data, side='right')]\n",
    "\t\tcdf2we = cwei2[np.searchsorted(data2, data, side='right')]\n",
    "\t\td = np.max(np.abs(cdf1we - cdf2we))\n",
    "\t\t# calculate p-value\n",
    "\t\tn1 = data1.shape[0]\n",
    "\t\tn2 = data2.shape[0]\n",
    "\t\tm, n = sorted([float(n1), float(n2)], reverse=True)\n",
    "\t\ten = m * n / (m + n)\n",
    "\t\tif alternative == 'two-sided':\n",
    "\t\t\tprob = distributions.kstwo.sf(d, np.round(en))\n",
    "\t\telse:\n",
    "\t\t\tz = np.sqrt(en) * d\n",
    "\t\t\t# Use Hodges' suggested approximation Eqn 5.3\n",
    "\t\t\t# Requires m to be the larger of (n1, n2)\n",
    "\t\t\texpt = -2 * z**2 - 2 * z * (m + 2*n)/np.sqrt(m*n*(m+n))/3.0\n",
    "\t\t\tprob = np.exp(expt)\n",
    "\t\treturn d, prob\n",
    "\t\n",
    "\tdef calc_pairwise_matrix(self, par_index):\n",
    "\t\tn_runs = len(self.all_runs)\n",
    "\t\tcombos = itertools.combinations(range(n_runs), 2)\n",
    "\t\tks_matrix = np.zeros(shape=(n_runs, n_runs))\n",
    "\t\tpval_matrix = np.zeros(shape=(n_runs, n_runs))\n",
    "\t\tfor i, j in combos:\n",
    "\t\t\trunA = self.all_runs[i]\n",
    "\t\t\trunB = self.all_runs[j]\n",
    "\t\t\tprint(f\"{runA.method}-{runA.seed}: {runA.posterior_weights.shape}\")\n",
    "\t\t\tprint(f\"{runB.method}-{runB.seed}: {runB.posterior_weights.shape}\")\n",
    "\t\t\tprint()\n",
    "\t\t\tparam_samplesA = runA.posterior_samples[:, par_index]\n",
    "\t\t\tparam_samplesB = runB.posterior_samples[:, par_index]\n",
    "\t\t\tks_stat, pval = self.ks_weighted(param_samplesA, param_samplesB,\n",
    "\t\t\t\t\t\t\t\t\t\t\trunA.posterior_weights, runB.posterior_weights)\n",
    "\t\t\tks_matrix[j, i] = ks_stat\n",
    "\t\t\tks_matrix[i, j] = ks_stat\n",
    "\t\t\tpval_matrix[j, i] = pval\n",
    "\t\t\tpval_matrix[i, j] = pval\n",
    "\t\treturn ks_matrix, pval_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_name = \"Michaelis_Menten\"\n",
    "methods = [\"smc\", \"pmc\", \"ptmcmc\"]\n",
    "\n",
    "mod_prob = ModelProblem(prob_name)\n",
    "mod_prob.initialize()\n",
    "\n",
    "grouped_results = [MethodResults(x) for x in methods]\n",
    "\n",
    "for method, group_obj in zip(methods, grouped_results):\n",
    "\tresult_dir = f\"results/{prob_name}/{method}/\"\n",
    "\tfnames = glob.glob(result_dir + \"*.pkl\")\n",
    "\tfor fname in fnames:\n",
    "\t\t#print(fname)\n",
    "\t\twith open(fname, \"rb\") as f:\n",
    "\t\t\tresults = pickle.load(f)\n",
    "\t\tresult_obj = Result(results)\n",
    "\t\tgroup_obj.add_result(result_obj)\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_par_names = mod_prob.problem.x_names\n",
    "all_ks_stats=[]\n",
    "\n",
    "ks_df = pd.DataFrame(columns=[\"Param\", \"Method\", \"KS\"])\n",
    "for i, name in enumerate(fit_par_names):\n",
    "\t# assumes all runs have the same model parameters\n",
    "\tfor runs in grouped_results:\n",
    "\t\tks_stats , pvals = runs.calc_pairwise_matrix(par_index=i)\n",
    "\t\tall_ks_stats.append(ks_stats[np.triu_indices(ks_stats.shape[0], k = 1)])\n",
    "\t\tfor run_ks in ks_stats:\n",
    "\t\t\tfor ks_stat in run_ks:\n",
    "\t\t\t\tnew_row = {\"Param\":name, \"Method\":runs.abbr, \"KS\":ks_stat}\n",
    "\t\t\t\tks_df.loc[len(ks_df)] = new_row\n",
    "\n",
    "print(ks_df.shape)\n",
    "ks_df = ks_df.drop(ks_df[ks_df[\"KS\"] == 0].index)\n",
    "print(ks_df.shape)\n",
    "\n",
    "sns.violinplot(data=ks_df, x=\"Param\", y=\"KS\", hue=\"Method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "calls = np.array([x.get_fun_calls() for x in grouped_results])\n",
    "call_df = pd.DataFrame(columns=methods, data=calls.T)\n",
    "sns.violinplot(call_df)\n",
    "plt.xticks(range(len(methods)), [x.abbr for x in grouped_results])\n",
    "plt.xlabel(\"Method\"); plt.ylabel(\"# of Objective Function Calls\");\n",
    "print(f\"MAX NUM FUNC CALLS: {np.max(calls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh_threshold = -170\n",
    "plt.figure(dpi=300)\n",
    "#grouped_results[0].get_convergence_times(llh_threshold)\n",
    "conv = np.array([x.get_convergence_times(llh_threshold) for x in grouped_results])\n",
    "conv_df = pd.DataFrame(columns=methods, data=conv.T)\n",
    "\n",
    "sns.swarmplot(conv_df)\n",
    "plt.xticks(range(len(methods)), [x.abbr for x in grouped_results])\n",
    "plt.xlabel(\"Method\"); \n",
    "plt.ylabel(f\"# Function Evaluations until Convergence\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the estimated parameters\n",
    "fit_par_names = mod_prob.problem.x_names\n",
    "par_bounds = mod_prob.bounds\n",
    "plt.figure(dpi=300)\n",
    "ratios = np.array([x.get_sampling_efficiency(par_bounds, 0) for x in grouped_results])\n",
    "ratio_df = pd.DataFrame(columns=methods, data=ratios.T)\n",
    "\n",
    "sns.swarmplot(ratio_df)\n",
    "plt.xticks(range(len(methods)), [x.abbr for x in grouped_results])\n",
    "plt.xlabel(\"Method\"); plt.ylabel(f\"% of Parameter Space Covered\\nfor Parameter {fit_par_names[0]} \");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the estimated parameters\n",
    "fit_par_names = mod_prob.problem.x_names\n",
    "par_bounds = mod_prob.bounds\n",
    "plt.figure(dpi=300)\n",
    "ratios = np.array([x.get_sampling_efficiency(par_bounds, 1) for x in grouped_results])\n",
    "ratio_df = pd.DataFrame(columns=methods, data=ratios.T)\n",
    "\n",
    "sns.swarmplot(ratio_df)\n",
    "plt.xticks(range(len(methods)), [x.abbr for x in grouped_results])\n",
    "plt.xlabel(\"Method\"); plt.ylabel(f\"% of Parameter Space Covered\\nfor Parameter {fit_par_names[1]} \");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llhs = np.array([x.get_llhs() for x in grouped_results])\n",
    "best_runs = [np.argmax(np.max(x, axis=1)) for x in llhs]\n",
    "best_results = [res.all_runs[best_idx] for best_idx, res in zip(best_runs, grouped_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_par_names = mod_prob.problem.x_names\n",
    "par_bounds = mod_prob.bounds\n",
    "colors = sns.color_palette(\"colorblind\", len(best_results))\n",
    "histtype = \"step\"\n",
    "alpha=1\n",
    "\n",
    "plt.figure(figsize=(10,4), dpi=300)\n",
    "for i, par_name in enumerate(fit_par_names): \n",
    "\tplt.subplot(int(f\"1{mod_prob.n_dim}{i+1}\"))\n",
    "\tfor j in range(len(best_results)):      \n",
    "\t\tcur_result = best_results[j]\n",
    "\t\tnorm_ws = cur_result.posterior_weights\n",
    "\t\tplt.hist(cur_result.posterior_samples[:, i], lw=2, weights=norm_ws, color=colors[j], alpha=alpha,\n",
    "\t\t\t cumulative=False, histtype=\"bar\", bins=50, label=cur_result.method) \n",
    "\t\tplt.xlabel(par_name)\n",
    "\t\tplt.yticks([])\n",
    "\t\tplt.ylabel(\"Density\")\n",
    "\t\tplt.margins(x=0)\n",
    "\tplt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the estimated parameters\n",
    "fit_par_names = mod_prob.problem.x_names\n",
    "par_bounds = mod_prob.bounds\n",
    "colors = sns.color_palette(\"colorblind\", len(best_results))\n",
    "histtype = \"bar\"\n",
    "alpha=0.5\n",
    "\n",
    "plt.figure(figsize=(10,4), dpi=300)\n",
    "for i, par_name in enumerate(fit_par_names): \n",
    "\tplt.subplot(int(f\"1{mod_prob.n_dim}{i+1}\"))\n",
    "\tfor j in range(len(best_results)):      \n",
    "\t\tcur_result = best_results[j]\n",
    "\t\tprint(np.sum(cur_result.posterior_weights))\n",
    "\t\tplt.hist(cur_result.posterior_samples[:, i], lw=2, weights=cur_result.posterior_weights, color=colors[j], alpha=alpha,\n",
    "\t\t\t cumulative=False, histtype=histtype, bins=40, label=cur_result.method) \n",
    "\t\tplt.xlabel(par_name)\n",
    "\t\tplt.yticks([])\n",
    "\t\tplt.ylabel(\"Density\")\n",
    "\t\tplt.margins(x=0)\n",
    "\tplt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# Get the names of the estimated parameters\n",
    "fit_par_names = mod_prob.problem.x_names\n",
    "par_bounds = mod_prob.bounds\n",
    "colors = sns.color_palette(\"colorblind\", len(best_results))\n",
    "histtype = \"bar\"\n",
    "alpha=0.5\n",
    "\n",
    "plt.figure(figsize=(10,4), dpi=300)\n",
    "for i, par_name in enumerate(fit_par_names): \n",
    "\tplt.subplot(int(f\"1{mod_prob.n_dim}{i+1}\"))\n",
    "\tfor j in range(len(best_results)):      \n",
    "\t\tcur_result = best_results[j]\n",
    "\t\tparam_samples = cur_result.posterior_samples[:, i]\n",
    "\t\tnorm_ws = cur_result.posterior_weights\n",
    "\t\tkde = st.gaussian_kde(param_samples, weights=norm_ws)\n",
    "\t\tx = np.linspace(np.min(param_samples), np.max(param_samples), 50)\n",
    "\t\tplt.plot(x, kde(x), '-', color=colors[j], alpha=0.75, zorder=1, label=cur_result.method)\n",
    "\t\tplt.fill_between(x, kde(x), alpha=0.25, color=colors[j], zorder=1)\n",
    "\t\t\n",
    "\t\tplt.xlabel(par_name)\n",
    "\t\tplt.yticks([])\n",
    "\t\tplt.ylabel(\"Density\")\n",
    "\t\tplt.margins(x=0, y=0.001)\n",
    "\tplt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "colors = sns.color_palette(\"colorblind\", len(best_results))\n",
    "for i, method in enumerate(methods):\n",
    "    cur_result = best_results[j]\n",
    "    param_samples = cur_result.posterior_samples\n",
    "    norm_ws = cur_result.posterior_weights #np.divide(cur_result.posterior_weights, np.sum(cur_result.posterior_weights))\n",
    "    corner.corner(param_samples, weights=norm_ws, color=colors[i], labels=fit_par_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the estimated parameters\n",
    "fit_par_names = mod_prob.problem.x_names\n",
    "par_bounds = mod_prob.bounds\n",
    "\n",
    "plt.figure(figsize=(10,8), dpi=300)\n",
    "fig_num = 1\n",
    "for j in range(len(best_results)):\n",
    "\tfor i, par_name in enumerate(fit_par_names):       \n",
    "\t\tcur_result = best_results[j]\n",
    "\t\t#print(f\"{i}\\t{cur_result.method}\")\n",
    "\t\t#print(int(f\"{len(best_results)}{mod_prob.n_dim}{fig_num}\"))\n",
    "\t\tplt.subplot(int(f\"{len(best_results)}{mod_prob.n_dim}{fig_num}\"))\n",
    "\t\tfig_num+=1\n",
    "\t\tn_iters = cur_result.n_iter\n",
    "\t\tn_chains = cur_result.n_chains\n",
    "\t\tn_dim = len(fit_par_names)\n",
    "\n",
    "\t\tcur_weights = cur_result.all_weights\n",
    "\t\tcur_trace = cur_result.all_samples[:, :, i]\n",
    "\t\titers = cur_result.iters\n",
    "\n",
    "\n",
    "\t\t# Left column -- beta plots\n",
    "\t\tfor q, it in enumerate(iters):\n",
    "\t\t\tif cur_result.method == \"ptmcmc\":\n",
    "\t\t\t\tif q % 100 != 0:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\tcolor='grey'\n",
    "\t\t\tif q == n_iters - 1:\n",
    "\t\t\t\tcolor='blue'\n",
    "\t\t\tplt.scatter(\n",
    "\t\t\t\tnp.full(n_chains, it),\n",
    "\t\t\t\tcur_trace[q, :],\n",
    "\t\t\t\ts=2,\n",
    "\t\t\t\tc=color,\n",
    "\t\t\t\t#alpha=cur_weights[q, :]\n",
    "\t\t\t)\n",
    "\t\n",
    "\t\t# Plot bounds\n",
    "\t\tplt.axhline(y=par_bounds[i][0], color='r', linestyle='--')\n",
    "\t\tplt.axhline(y=par_bounds[i][1], color='r', linestyle='--')\n",
    "\t\tplt.ylabel(\"$\\\\log_{10}$(%s)\"%par_name)\n",
    "\t\tif cur_result.method != \"ptmcmc\":\n",
    "\t\t\tplt.xscale('log')\n",
    "\t\t\tplt.xlabel(r'$\\beta$ (Iteration)')\n",
    "\t\telse:\n",
    "\t\t\tplt.xlabel(\"Iteration Number\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
