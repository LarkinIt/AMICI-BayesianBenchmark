{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare methods notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sys import getsizeof\n",
    "from objsize import get_deep_size\n",
    "import matplotlib.pyplot as plt\n",
    "from modelproblem import ModelProblem\n",
    "from result_classes import Result,MethodResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/Calcium_Oscillate/smc/Calcium_Oscillate_smc_0seed.pkl:\t14155424\t2846\n",
      "results/Calcium_Oscillate/pmc/Calcium_Oscillate_pmc_0seed.pkl:\t12475136\t2818\n",
      "results/Calcium_Oscillate/ptmcmc/Calcium_Oscillate_ptmcmc_0seed.pkl:\t954029554\t2169\n",
      "<class 'pypesto.problem.base.Problem'>\n"
     ]
    }
   ],
   "source": [
    "prob_name = \"Calcium_Oscillate\"\n",
    "methods = [\"smc\", \"pmc\", \"ptmcmc\"]\n",
    "\n",
    "mod_prob = ModelProblem(prob_name)\n",
    "mod_prob.initialize()\n",
    "\n",
    "grouped_results = [MethodResults(x) for x in methods]\n",
    "\n",
    "for method, group_obj in zip(methods, grouped_results):\n",
    "\tresult_dir = f\"results/{prob_name}/{method}/\"\n",
    "\tfnames = glob.glob(result_dir + \"*.pkl\")\n",
    "\tfor fname in fnames:\n",
    "\t\twith open(fname, \"rb\") as f:\n",
    "\t\t\tresults = pickle.load(f)\n",
    "\t\t\tprint(f\"{fname}:\\t{os.path.getsize(fname)}\\t{get_deep_size(results)}\")\n",
    "\t\tresult_obj = Result(results)\n",
    "\t\tgroup_obj.add_result(result_obj)\n",
    "\t\tbreak\n",
    "print(type(mod_prob.problem))\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the percentage of runs that converged in PT-MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\tptmcmc_idx = methods.index(\"ptmcmc\")\n",
    "\tptmcmc_group = grouped_results[ptmcmc_idx]\n",
    "\tn_runs = len(ptmcmc_group.all_runs)\n",
    "\tn_converged = 0\n",
    "\tfor i in range(n_runs):\n",
    "\t\tif ptmcmc_group.all_runs[i].converged:\n",
    "\t\t\tn_converged+=1\n",
    "\tprint(f\"{n_converged:d} of {n_runs:d} runs have converged\\nConvergence percentage: {n_converged/n_runs:.2f}\")\n",
    "except ValueError:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the distribution of ALL likelihoods from ALL runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "llhs = np.array([x.get_llhs().flatten() for x in grouped_results], dtype=object)\n",
    "\n",
    "\n",
    "#llhs[llhs<-20000] = -7500\n",
    "llh_df = pd.DataFrame()\n",
    "#plt.boxplot(x=range(1,len(methods)+1), llhs, showfliers=False)\n",
    "for llh_arr, method in zip(llhs, methods):\n",
    "\tllh_df[method] = llh_arr\n",
    "\n",
    "sns.boxplot(llh_df, showfliers=False)\n",
    "plt.xlabel(\"Method\"); plt.ylabel(\"log likelihood\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "calls = np.array([x.get_fun_calls() for x in grouped_results])\n",
    "call_df = pd.DataFrame(columns=methods, data=calls.T)\n",
    "sns.violinplot(call_df)\n",
    "plt.xticks(range(len(methods)), [x.abbr for x in grouped_results])\n",
    "plt.xlabel(\"Method\"); plt.ylabel(\"# of Objective Function Calls\");\n",
    "print(f\"MAX NUM FUNC CALLS: {np.max(calls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from objsize import get_deep_size\n",
    "bytes = 0\n",
    "pmc_bytes=0\n",
    "pmc_res = grouped_results[1].all_runs[7]\n",
    "ptmcmc_res = grouped_results[2].all_runs[7]\n",
    "for key in ptmcmc_res.__dict__.keys():\n",
    "\tpmc_val = pmc_res.__dict__[key]\n",
    "\tptmcmc_val = ptmcmc_res.__dict__[key]\n",
    "\ta = get_deep_size(pmc_val)\n",
    "\ts = get_deep_size(ptmcmc_val)\n",
    "\n",
    "\tprint(f\"{key}:\\tPMC->{a}\\tPTMCMC->{s}\")\n",
    "\n",
    "\tif isinstance(pmc_val, dict):\n",
    "\t\tfor keydos in pmc_val.keys():\n",
    "\t\t\tb = get_deep_size(pmc_val[keydos])\n",
    "\t\t\tprint(f\"\\t\\t{keydos}:\\tPMC->{b}\")\n",
    "\tif isinstance(ptmcmc_val, dict):\n",
    "\t\tfor keydos in ptmcmc_val.keys():\n",
    "\t\t\tc = get_deep_size(ptmcmc_val[keydos])\n",
    "\t\t\tprint(f\"\\t\\t{keydos}:\\tPTMCMC->{c}\")        \n",
    "\tif isinstance(pmc_val, list) or isinstance(pmc_val, np.ndarray):\n",
    "\t\tprint(\"\\t\\t PMC:\", pmc_val.dtype)\n",
    "\tif isinstance(ptmcmc_val, list) or isinstance(ptmcmc_val, np.ndarray):\n",
    "\t\tprint(\"\\t\\t PTMCMC:\", ptmcmc_val.dtype)\n",
    "\tpmc_bytes+=a\n",
    "\tbytes+=s\n",
    "print(f\"TOTAL: {pmc_bytes} {bytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh_threshold = -100000\n",
    "grouped_results[1].get_convergence_times(llh_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh_threshold = -2000\n",
    "plt.figure(dpi=300)\n",
    "#grouped_results[0].get_convergence_times(llh_threshold)\n",
    "conv = np.array([x.get_convergence_times(llh_threshold) for x in grouped_results])\n",
    "conv_df = pd.DataFrame(columns=methods, data=conv.T)\n",
    "\n",
    "sns.swarmplot(conv_df)\n",
    "plt.xticks(range(len(methods)), [x.abbr for x in grouped_results])\n",
    "plt.xlabel(\"Method\"); \n",
    "plt.ylabel(f\"# Function Evaluations until Convergence\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
