{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mRNA self-regulation Specific Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from modelproblem import ModelProblem\n",
    "from petab.visualize import plot_problem\n",
    "from weighted_quantile import weighted_quantile\n",
    "from result_classes import Result,MethodResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_name = \"Calcium_Oscillate\"\n",
    "methods = [\"smc\", \"pmc\"]#, \"ptmcmc\"]\n",
    "colors = sns.color_palette(\"tab10\", n_colors=len(methods))\n",
    "\n",
    "mod_prob = ModelProblem(prob_name)\n",
    "mod_prob.initialize()\n",
    "\n",
    "grouped_results = [MethodResults(x) for x in methods]\n",
    "\n",
    "for method, group_obj in zip(methods, grouped_results):\n",
    "\tresult_dir = f\"results/{prob_name}/{method}/\"\n",
    "\tfnames = glob.glob(result_dir + \"*.pkl\")\n",
    "\tfor fname in fnames:\n",
    "\t\t#print(fname)\n",
    "\t\twith open(fname, \"rb\") as f:\n",
    "\t\t\tresults = pickle.load(f)\n",
    "\t\tresult_obj = Result(results)\n",
    "\t\tgroup_obj.add_result(result_obj)\n",
    "print(type(mod_prob.problem))\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_idxs = mod_prob.problem.x_fixed_indices\n",
    "par_names = mod_prob.problem.x_names\n",
    "x=np.array(par_names)\n",
    "mask=np.full(len(par_names),True,dtype=bool)\n",
    "mask[fixed_idxs]=False\n",
    "fit_par_names=x[mask]\n",
    "\n",
    "dummy_idx = -1\n",
    "\n",
    "par_bounds = mod_prob.bounds\n",
    "plt.figure(dpi=300)\n",
    "ratios = np.array([x.get_sampling_efficiency(par_bounds, dummy_idx) for x in grouped_results])\n",
    "ratio_df = pd.DataFrame(columns=methods, data=ratios.T)\n",
    "\n",
    "sns.violinplot(ratio_df)#, size=2)\n",
    "plt.xticks(range(len(methods)), [x.abbr for x in grouped_results])\n",
    "plt.xlabel(\"Method\"); plt.ylabel(f\"% of Parameter Space Covered\\nfor Parameter {fit_par_names[-1]} \");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select best result for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llhs = np.array([x.get_llhs() for x in grouped_results])\n",
    "best_runs = [np.argmax(np.max(x, axis=1)) for x in llhs]\n",
    "best_results = [res.all_runs[best_idx] for best_idx, res in zip(best_runs, grouped_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_idxs = mod_prob.problem.x_fixed_indices\n",
    "par_names = mod_prob.problem.x_names\n",
    "x=np.array(par_names)\n",
    "mask=np.full(len(par_names),True,dtype=bool)\n",
    "mask[fixed_idxs]=False\n",
    "fit_par_names=x[mask]\n",
    "\n",
    "par_bounds = mod_prob.bounds\n",
    "histtype = \"step\"\n",
    "alpha=1\n",
    "\n",
    "plt.figure(figsize=(18,18), dpi=300)\n",
    "for i, par_name in enumerate(fit_par_names): \n",
    "\tplt.subplot(4,4,i+1)\n",
    "\tfor j in range(len(best_results)):      \n",
    "\t\tcur_result = best_results[j]\n",
    "\t\tnorm_ws = cur_result.posterior_weights\n",
    "\t\tplt.hist(cur_result.posterior_samples[:, i], lw=2, weights=norm_ws, color=colors[j], alpha=alpha,\n",
    "\t\t\t cumulative=True, histtype=\"step\", bins=50, label=cur_result.method) \n",
    "\t\tplt.xlabel(par_name)\n",
    "\t\tplt.yticks([])\n",
    "\t\tplt.ylabel(\"Density\")\n",
    "\t\tplt.margins(x=0)\n",
    "\tplt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the estimated parameters\n",
    "fixed_idxs = mod_prob.problem.x_fixed_indices\n",
    "par_names = mod_prob.problem.x_names\n",
    "x=np.array(par_names)\n",
    "mask=np.full(len(par_names),True,dtype=bool)\n",
    "mask[fixed_idxs]=False\n",
    "fit_par_names=x[mask]\n",
    "\n",
    "par_bounds = mod_prob.bounds\n",
    "histtype = \"bar\"\n",
    "alpha=0.5\n",
    "\n",
    "plt.figure(figsize=(10,12), dpi=300)\n",
    "for i, par_name in enumerate(fit_par_names): \n",
    "\tplt.subplot(4,4,i+1)\n",
    "\tfor j in range(len(best_results)):      \n",
    "\t\tcur_result = best_results[j]\n",
    "\t\tplt.hist(cur_result.posterior_samples[:, i], lw=2, weights=cur_result.posterior_weights, color=colors[j], alpha=alpha,\n",
    "\t\t\t cumulative=False, histtype=histtype, bins=40, label=cur_result.method) \n",
    "\t\tplt.xlabel(par_name)\n",
    "\t\tplt.yticks([])\n",
    "\t\tplt.ylabel(\"Density\")\n",
    "\t\tplt.margins(x=0)\n",
    "\tplt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# Get the names of the estimated parameters\n",
    "fixed_idxs = mod_prob.problem.x_fixed_indices\n",
    "par_names = mod_prob.problem.x_names\n",
    "x=np.array(par_names)\n",
    "mask=np.full(len(par_names),True,dtype=bool)\n",
    "mask[fixed_idxs]=False\n",
    "fit_par_names=x[mask]\n",
    "\n",
    "par_bounds = mod_prob.bounds\n",
    "histtype = \"bar\"\n",
    "alpha=0.5\n",
    "xtrue = mod_prob.petab_problem.get_x_nominal(fixed=False, scaled=False)\n",
    "plt.figure(figsize=(16,16), dpi=300)\n",
    "for i, par_name in enumerate(fit_par_names): \n",
    "\tplt.subplot(4,4,i+1)\n",
    "\tfor j in range(len(best_results)):      \n",
    "\t\tcur_result = best_results[j]\n",
    "\t\tparam_samples = cur_result.posterior_samples[:, i]\n",
    "\t\tnorm_ws = cur_result.posterior_weights\n",
    "\t\tkde = st.gaussian_kde(param_samples, weights=norm_ws)\n",
    "\t\tx = np.linspace(np.min(param_samples), np.max(param_samples), 50)\n",
    "\t\tplt.plot(x, kde(x), '-', color=colors[j], alpha=0.75, zorder=1, label=cur_result.method)\n",
    "\t\tplt.fill_between(x, kde(x), alpha=0.25, color=colors[j], zorder=1)\n",
    "\t\n",
    "\tplt.axvline(x=xtrue[i], ls=\"--\", color=\"k\", label=\"Nominal\")\n",
    "\tplt.xlabel(par_name)\n",
    "\tplt.yticks([])\n",
    "\tplt.ylabel(\"Density\")\n",
    "\t#plt.margins(x=0, y=0.001)\n",
    "\tplt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "for i, method in enumerate(methods):\n",
    "\tcur_result = best_results[j]\n",
    "\tparam_samples = cur_result.posterior_samples\n",
    "\tnorm_ws = cur_result.posterior_weights #np.divide(cur_result.posterior_weights, np.sum(cur_result.posterior_weights))\n",
    "\tcorner.corner(param_samples, weights=norm_ws, color=colors[i], labels=fit_par_names)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the estimated parameters\n",
    "fixed_idxs = mod_prob.problem.x_fixed_indices\n",
    "par_names = mod_prob.problem.x_names\n",
    "x=np.array(par_names)\n",
    "mask=np.full(len(par_names),True,dtype=bool)\n",
    "mask[fixed_idxs]=False\n",
    "fit_par_names=x[mask]\n",
    "\n",
    "par_bounds = mod_prob.bounds\n",
    "xtrue = mod_prob.petab_problem.get_x_nominal(fixed=False, scaled=False)\n",
    "\n",
    "plt.figure(figsize=(12,7), dpi=300)\n",
    "fig_num = 1\n",
    "for j in range(len(best_results)):\n",
    "\tfor i, par_name in enumerate(fit_par_names):       \n",
    "\t\tcur_result = best_results[j]\n",
    "\t\t#print(f\"{i}\\t{cur_result.method}\")\n",
    "\t\t#print(int(f\"{len(best_results)}{mod_prob.n_dim}{fig_num}\"))\n",
    "\t\tplt.subplot(int(len(best_results)), int(mod_prob.n_dim), fig_num)\n",
    "\t\tfig_num+=1\n",
    "\t\tn_iters = cur_result.n_iter\n",
    "\t\tn_chains = cur_result.n_chains\n",
    "\t\tn_dim = len(fit_par_names)\n",
    "\n",
    "\t\tcur_weights = cur_result.all_weights\n",
    "\t\tcur_trace = cur_result.all_samples[:, :, i]\n",
    "\t\titers = cur_result.iters\n",
    "\n",
    "\n",
    "\t\t# Left column -- beta plots\n",
    "\t\tfor q, it in enumerate(iters):\n",
    "\t\t\tif cur_result.method == \"ptmcmc\":\n",
    "\t\t\t\tif q % 100 != 0:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\tcolor='grey'\n",
    "\t\t\tif q == n_iters - 1:\n",
    "\t\t\t\tcolor='blue'\n",
    "\t\t\tplt.scatter(\n",
    "\t\t\t\tnp.full(n_chains, it),\n",
    "\t\t\t\tcur_trace[q, :],\n",
    "\t\t\t\ts=2,\n",
    "\t\t\t\tc=color,\n",
    "\t\t\t\t#alpha=cur_weights[q, :]\n",
    "\t\t\t)\n",
    "\t\n",
    "\t\t# Plot bounds\n",
    "\t\tplt.axhline(y=par_bounds[i][0], color='r', linestyle='--')\n",
    "\t\tplt.axhline(y=par_bounds[i][1], color='r', linestyle='--')\n",
    "\t\tplt.axhline(y=xtrue[i], color=\"g\", lw=2)\n",
    "\t\tplt.ylabel(par_name)\n",
    "\t\tif cur_result.method != \"ptmcmc\":\n",
    "\t\t\tplt.xscale('log')\n",
    "\t\t\tplt.xlabel(r'$\\beta$ (Iteration)')\n",
    "\t\telse:\n",
    "\t\t\tplt.xlabel(\"Iteration Number\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypesto.objective import AggregatedObjective\n",
    "from pypesto.objective.roadrunner.road_runner import RoadRunnerObjective\n",
    "obj = mod_prob.problem.objective\n",
    "og_obj = obj\n",
    "if isinstance(obj, AggregatedObjective):\n",
    "    subobjs = mod_prob.problem.objective.__dict__[\"_objectives\"]\n",
    "    for subobj in subobjs:\n",
    "        if isinstance(subobj, RoadRunnerObjective):\n",
    "            obj = subobj\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fits to model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = 0.95\n",
    "UPPER_PCT = (1 - (1-CI)/2)\n",
    "LOWER_PCT = ((1-CI)/2)\n",
    "\n",
    "petab_prob = mod_prob.petab_problem\n",
    "ax_dict = plot_problem(petab_problem=petab_prob,) \n",
    "fig = plt.gcf()\n",
    "# Change the figure size\n",
    "fig.set_size_inches(6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = petab_prob.measurement_df\n",
    "plt.figure(figsize=(6,4), dpi=300)\n",
    "plt.plot(measure_df[\"time\"], measure_df[\"measurement\"], \"ko\", label=\"Data\", zorder=2)\n",
    "lss = [(0,(5,10)), (0,(3,5,1,5)), (0,(1,4))]\n",
    "for i, best in enumerate(best_results):\n",
    "\tpars = best.posterior_samples\n",
    "\tweights = best.posterior_weights\n",
    "\n",
    "\tall_sim_data = np.empty(shape=(measure_df.shape[0], pars.shape[0]))\n",
    "\n",
    "\t## Collect all of the runs simulation information\n",
    "\tfor n, par in enumerate(pars):\n",
    "\t\tsim = obj(par, mode=\"mode_fun\", return_dict=True)[\"simulation_results\"][\"simCondition\"]\n",
    "\t\tall_sim_data[:, n] = sim[:, 1]\n",
    "\t\tsim_ts = sim[:, 0]\n",
    "\t\t\n",
    "\tn_ts = len(sim_ts)\n",
    "\tmean_sim_data = np.average(all_sim_data, weights=weights, axis=1)\n",
    "\ttemp = np.array([weighted_quantile(x, [LOWER_PCT, UPPER_PCT], weights) for x in all_sim_data])\n",
    "\t#print(temp[0])\n",
    "\tlow_sim_data = temp[:, 0]\n",
    "\thigh_sim_data = temp[:, 1]\n",
    "\n",
    "\tplt.plot(sim_ts, mean_sim_data, lw=3, linestyle=lss[i], label=best.method, zorder=1, color=colors[i])\n",
    "\tplt.fill_between(sim_ts, low_sim_data, high_sim_data, zorder=3, alpha=0.3, color=colors[i])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\"); plt.ylabel(\"[Ca]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_df = petab_prob.measurement_df\n",
    "plt.figure(figsize=(6,4), dpi=300)\n",
    "plt.plot(measure_df[\"time\"], measure_df[\"measurement\"], \"ko\", label=\"Data\", zorder=2)\n",
    "\n",
    "max_t = np.max(measure_df[\"time\"])\n",
    "n_sim_ts = int(16*100 + 1)\n",
    "simu = obj.roadrunner_instance\n",
    "print(simu.model.getFloatingSpeciesIds())\n",
    "\n",
    "lss = [(0,(5,10)), (0,(3,5,1,5)), (0,(1,4))]\n",
    "for i, best in enumerate(best_results):\n",
    "\tpars = best.posterior_samples\n",
    "\tweights = best.posterior_weights\n",
    "\n",
    "\tall_sim_data = np.empty(shape=(n_sim_ts, pars.shape[0]))\n",
    "\n",
    "\t## Collect all of the runs simulation information\n",
    "\tfor n, par in enumerate(pars):\n",
    "\t\t#sim = obj(par, mode=\"mode_fun\", return_dict=True)[\"simulation_results\"][\"simCondition\"]\n",
    "\t\tsimu.resetAll()\n",
    "\t\tfor name, x in zip(fit_par_names, par):\n",
    "\t\t\tsimu[name] = x\n",
    "\t\tsimu.reset()\n",
    "\t\tsim = simu.simulate(0, 16, n_sim_ts)\n",
    "\t\tall_sim_data[:, n] = sim[:, 1]\n",
    "\t\tsim_ts = sim[:, 0]\n",
    "\tn_ts = len(sim_ts)\n",
    "\tmean_sim_data = np.average(all_sim_data, weights=weights, axis=1)\n",
    "\ttemp = np.array([weighted_quantile(x, [LOWER_PCT, UPPER_PCT], weights) for x in all_sim_data])\n",
    "\t#print(temp[0])\n",
    "\tlow_sim_data = temp[:, 0]\n",
    "\thigh_sim_data = temp[:, 1]\n",
    "\t\n",
    "\tplt.plot(sim_ts, mean_sim_data, lw=3, linestyle=lss[i], label=best.method, zorder=1, color=colors[i])\n",
    "\tplt.fill_between(sim_ts, low_sim_data, high_sim_data, zorder=3, alpha=0.3, color=colors[i])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\"); plt.ylabel(\"[Ca]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
