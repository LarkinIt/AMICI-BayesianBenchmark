{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michaelis-Menten Model Calibration Notebook\n",
    "\n",
    "Based on PTemPest example written in Matlab [here](https://github.com/RuleWorld/ptempest/tree/master/examples/michment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This system describes the 1) reversible binding of an enzyme to substrate and 2) production of substrate product which is defined in the following scheme:  \n",
    "$$E + S \\rightleftharpoons^{k_f}_{k_r} ES \\longrightarrow^{k_{cat}} E + P$$  \n",
    "\n",
    "Assuming total enzyme concentration is significantly smaller than substrate concentration (i.e., $[E]_T \\ll [S]$), the rate is defined as:  \n",
    "$$\\frac{d[P]}{dt} = \\frac{k_{cat}[E]_T[S]}{K_M + [S]}$$\n",
    "where $K_M = \\frac{k_{cat} + k_r}{k_f}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Calibration\n",
    "\n",
    "The following notebook calibrates the Michaelis-Menten model system using synthetically generated data with 1% Gaussian error. Here, we test the following inference methods:\n",
    "1. Metropolis-Hastings (`pyPESTO`)\n",
    "2. Parallel-Tempering MCMC (`pyPESTO`)\n",
    "3. Nested Sampling (`dynesty`)\n",
    "4. Sequential Monte Carlo (`pocoMC`)\n",
    "5. Preconditioned Monte Carlo (`pocoMC`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import roadrunner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import qmc\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pocomc as pc\n",
    "import dynesty as dy\n",
    "import pypesto as pype\n",
    "import pypesto.engine as eng\n",
    "import pypesto.sample as sample\n",
    "import pypesto.store as store\n",
    "import pypesto.optimize as optimize\n",
    "from pypesto.ensemble import Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `Model` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model class has the following attributes:\n",
    "1. `x_n` : `int`\n",
    "    Number of species in the model\n",
    "2. `fit_x0` : `bool`\n",
    "    Whether the initial conditions are to be estimated and are therefore include in `theta` args.\n",
    "3. `x0` : `list[float], optional`\n",
    "    The initial conditions of model species\n",
    "4. `theta_n` : `int`\n",
    "    Number of parameters to be fit. This includes ALL parameters to be estimated which MAY include initial conditions and the standard deviation of the model species. The order of the model parameters in this list is assumed to be as follows:\n",
    "    1. ODE equation parameters\n",
    "    2. Initial conditions (denoted $x_\\#$, **optional**)\n",
    "    3. Species standard deviations (denoted $\\sigma_\\#$)\n",
    "5. `theta_true` : `list[float]` of shape `(theta_n)`\n",
    "    True theta values of the model system. The order of \n",
    "6. `theta_names` : `list[str]` of shape `(theta_n)`\n",
    "    Name of parameters for plotting purposes\n",
    "7. `lower_bnds` : `list[float]` of shape `(theta_n)`\n",
    "    Lower bounds of parameter values \n",
    "8. `upper_bnds` : `list[float]` of shape `(theta_n)`\n",
    "    Upper bounds of parameter values \n",
    "9. `ts` : `list[float]` \n",
    "    Experimental data times \n",
    "10. `data` : `list[float]` of shape `(x_n, ts)` \n",
    "    Experimental data used for model calibration\n",
    "11. `sys_fun` : `callable` \n",
    "    Model function used to solve system ODEs. It will be called by `solve_ivp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, opts): #initial settings\n",
    "        for key in opts: #loops for all labels in the list 'key'\n",
    "            setattr(self, key, opts[key]) #creates a dictionary where 'key' are the list of labels & 'ops[key]' are the values\n",
    "\n",
    "    def __call__(self, theta_new):\n",
    "        theta_new = theta_new\n",
    "        res = self.log_likelihood(theta_new)\n",
    "        return res\n",
    "    \n",
    "    def run_sim(self, model_param = None, x0=None): #takes in canidate parameters then solves the ode\n",
    "        if model_param is None:\n",
    "            model_param= self.theta_true[:self.ODE_params_n]  #sets the model_params to just the model parameters\n",
    "        if x0 is None:\n",
    "            x0 = self.x0 #if x0 not defined, default x0 to the model x0\n",
    "        t_span = (self.ts[0], self.ts[-1]) #define the time span\n",
    "        x_n = self.x_n \n",
    "        \n",
    "        result = solve_ivp(self.sys_fun, t_span, y0=x0, \n",
    "                        t_eval=self.ts, args=([model_param])) #solve ODE (with model parameters)\n",
    "        \n",
    "        return result #returns result.t and result.y\n",
    "    \n",
    "    def log_prior(self, theta_new): \n",
    "        bools = [(low <= i <= high) for i,low,high in zip(theta_new, self.lower_bnds, self.upper_bnds)] #if generated values are within bounds\n",
    "        all_in_range = np.all(bools) #if all values are true, then output is true\n",
    "        if all_in_range: #if true\n",
    "            return 0.0 #give 0\n",
    "        return -np.inf #if even one parameter out of bounds, it's false, and returns -infinity\n",
    "\n",
    "    def log_likelihood(self, theta_new): #how good is this canidate parameter fitting my data (maximize it)\n",
    "        model_param = theta_new[:self.ODE_params_n] \n",
    "        if self.fit_x0: \n",
    "            x0 = theta_new[self.ODE_params_n:(self.ODE_params_n + self.x_n)] #sets x0 to 'theta_true' x0 values\n",
    "        else:\n",
    "            x0 = self.x0\n",
    "\n",
    "        if self.fit_sigma:\n",
    "            sigma = theta_new[-len(self.observable_index):] #observable index related to sigma\n",
    "        else:\n",
    "            sigma = [1] * len(self.observable_index) #makes all sigmas default to 1\n",
    "\n",
    "        y = self.run_sim(model_param=model_param, x0= x0).y #sets y to the y results of solving ODE\n",
    "        data = self.data #sets data\n",
    "        if self.x_n > 1:\n",
    "            y = np.transpose(y)\n",
    "\n",
    "        # Calculate posterior; how good is parameter in terms of fitting the data\n",
    "        term1 = -0.5 * np.log(2*np.pi*np.square(sigma))\n",
    "        term2 = np.square(np.subtract(y, data)) / (2*np.square(sigma))\n",
    "        logLH = np.sum(term1 - term2)\n",
    "        return logLH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
