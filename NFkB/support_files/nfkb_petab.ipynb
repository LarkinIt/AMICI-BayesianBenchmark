{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coding the NF-kB model from sanjana's thesis in PEtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import petab\n",
    "import bionetgen as bng\n",
    "from petab import Problem\n",
    "from petab.visualize import plot_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding NF-kB model in PEtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model class \n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, opts): #initial settings\n",
    "        for key in opts: #loops for all labels in the list 'key'\n",
    "            setattr(self, key, opts[key]) #creates a dictionary where 'key' are the list of labels & 'ops[key]' are the values\n",
    "        # Default model output to times and experimental observables\n",
    "        self.defaultOutput= ['time'] + self.observables\n",
    "        self.n_params= len(self.params)\n",
    "        self.n_obs= len(self.observables)\n",
    "        self.time_units= 'minutes'\n",
    "        self.time_conv= 60 # conversion factor for seconds to minutes\n",
    "\n",
    "    def __call__(self, theta_new):\n",
    "        theta_new = theta_new\n",
    "        res = self.log_likelihood(theta_new)\n",
    "        return res\n",
    "    \n",
    "    def add_data(self, df):\n",
    "        self.data= df\n",
    "\n",
    "    def run(self, dose=None, times=None, params=None, output=None): # 5ng dose?, Five minute time pulse, should be same as in the experimental data\n",
    "        rr = self.rr # rr calls upon the road runner simulation\n",
    "        rr.resetAll()\n",
    "        #rr.integrator.absolute_tolerance = 1e-12\n",
    "        #rr.integrator.relative_tolerance = 1e-12\n",
    "        \n",
    "        ##addZero=False\n",
    "\n",
    "        # Use timepoints of data as default times at which to get sim output\n",
    "        if params is None:\n",
    "            params= self.p_true # Sets the parameters as the true parameters. \n",
    "        if dose is None:\n",
    "            dose= self.dose\n",
    "        if times is None:\n",
    "            times= self.times #np.array(list(self.data['time'].values))\n",
    "        # make sure zero is first time point\n",
    "        if times[0]>0.0:\n",
    "\n",
    "            times = np.insert(times, 0, 0.0)\n",
    "\n",
    "            # addZero= True\n",
    "            # times= [0] + times\n",
    "            \n",
    "        # # Scale times to internal time units for model (seconds)\n",
    "        # try: \n",
    "        #     ind_pulse= np.where(times==tpulse)[0][0]\n",
    "        # except:\n",
    "        #     print(f\"No time point matching {tpulse} found in times\")\n",
    "        #     return([])\n",
    "        \n",
    "\n",
    "        # Set default output are the column names of the data\n",
    "        if output is None:\n",
    "            output= self.defaultOutput\n",
    "       \n",
    "        # Set parameter values\n",
    "        for name, value in zip(self.params, params):\n",
    "            rr[name] = float(value)\n",
    "        rr.reset()  # Necessary to be able to update the initial conditions\n",
    "\n",
    "        # ## DEBUG Statements\n",
    "        # # prints parameter values and initial conditions\n",
    "        # print(\"parameters used in the simulation:\")\n",
    "        # for name, value in zip(self.params, params):\n",
    "        #     print(f\"{name}: {value}\")\n",
    "\n",
    "        # print(f\"initial conditions (with dose):\")\n",
    "        # print(f\"L0: {dose}\")\n",
    "        # for species in rr.model.getFloatingSpeciesIds():\n",
    "        #     print(f\"{species}: {rr[species]}\")\n",
    "\n",
    "\n",
    "        # NOTE: If you want to vary the initial conditions, do this by defining\n",
    "        # a parameter in the model that sets the initial concentration of\n",
    "        # species and then include this parameter in your list of parameters to\n",
    "        # fit. \n",
    "        # Run trajectories\n",
    "        try:\n",
    "            # # First equilibrate the trajectory TNF set to zero\n",
    "            # rr.simulate(times=np.linspace(0,100, 101))\n",
    "            #  # set the dose for the IL-6 (L0) dose\n",
    "            # rr.L0=dose\n",
    "            rr['L0']=dose\n",
    "            # rr[\"init([L])\"]=dose\n",
    "            rr.reset()\n",
    "            res= rr.simulate(times=times,selections=output)\n",
    "            # rr.L0=dose\n",
    "            # rr.L0_IC=0\n",
    "            # res2= rr.simulate(times=times[ind_pulse:],selections=output)\n",
    "            # traj =  np.vstack((res1,res2[1:,:])) # skip duplicate point at pulse end point\n",
    "        except Exception as e:\n",
    "            # If integration fails return empty array\n",
    "            print(f\"Simulation failed: {e}\")\n",
    "            return []\n",
    "\n",
    "        return(res)\n",
    "        \n",
    "    def log_prior(self, theta_new): \n",
    "        bools = [(low <= i <= high) for i,low,high in zip(theta_new, self.lower_bnds, self.upper_bnds)] #if generated values are within bounds\n",
    "        all_in_range = np.all(bools) #if all values are true, then output is true\n",
    "        if all_in_range: \n",
    "            return 0.0 \n",
    "        return -np.inf #if even one parameter out of bounds, it's false, and returns -infinity\n",
    "\n",
    "    def log_likelihood(self, params): #how good is this candidate parameter fitting my data (maximize it)\n",
    "        y = self.run(params=params) #sets y to the y results of solving ODE\n",
    "        if (len(y)==0):\n",
    "            # return large (but not infinite value) if integration fails\n",
    "            return(-1e11)\n",
    "        if (np.any(np.isnan(y))):\n",
    "            return(-1e12)\n",
    "        # Compute fold change (CAUTION: works only if there is only one observable being fit)\n",
    "        y= y[1:,1]/y[0][1]\n",
    "        # Original that allows for multiple observables\n",
    "        #y= y[1:,1:]\n",
    "\n",
    "        #sets data (CAUTION: just fitting fold change of one variable)\n",
    "        #obs = self.data.values[1:,1] # Do not divide by the start is already using fold change data \n",
    "        obs= self.data[self.observables[0]].values[1:]\n",
    "        # Better default choice for multiobjective fit to use relative error\n",
    "        sigma= 1 #obs\n",
    "        #sigma = np.array([1] * len(self.observables)) #makes all sigmas default to 1\n",
    "        #print(sigma.shape)\n",
    "        #print(y-obs)\n",
    "        #print(y)\n",
    "        #print(obs)\n",
    "        ll= -np.sum(((y-obs)/(sigma))**2)# chi^2\n",
    "        return(ll)\n",
    "    \n",
    "    def calc_cost(self, params):\n",
    "\n",
    "        total_cost = 0\n",
    "\n",
    "        for i, (key, current_dose) in enumerate(zip(pSTAT1_dict.keys(), doses)):\n",
    "\n",
    "            # extract experimental data\n",
    "            mod_df = pSTAT1_dict[key]\n",
    "            # print(\"data:\", mod_df)\n",
    "            exp_times = pd.DataFrame(mod_df['time'])\n",
    "            # print(\"time:\", exp_time)\n",
    "            exp_pSTAT = pd.DataFrame(mod_df['STATp'])\n",
    "            # print(\"exp values:\", exp_pSTAT)\n",
    "\n",
    "            # run simulation \n",
    "            res = self.run(dose=current_dose, params=params)\n",
    "            res = pd.DataFrame(res)\n",
    "            # print(res)\n",
    "            res.columns = ['time', 'STATp']\n",
    "            # print(type(res))\n",
    "\n",
    "            ## get the simulated data that matches the experimental data\n",
    "            predicted_matches = res[res['time'].isin(exp_times['time'])]\n",
    "            # print(predicted_matches)\n",
    "            pred_values = pd.DataFrame(predicted_matches['STATp'])\n",
    "            pred_values = pred_values.rename(columns={'STATp':'predicted'})\n",
    "            # print(pred_values)\n",
    "            # predicted values are aligned with the time points\n",
    "            pred_values = pred_values.reset_index(drop=True)\n",
    "            # print(pred_values)\n",
    "\n",
    "            data_4_cost = pd.concat([exp_times.reset_index(drop=True), exp_pSTAT.reset_index(drop=True), pred_values], axis=1)\n",
    "            data_4_cost.columns = ['time', 'experimental', 'predicted']\n",
    "            # print(data_4_cost)\n",
    "\n",
    "            \n",
    "            # calculate the cost for the current dose\n",
    "            cost = cost_function(data_4_cost)\n",
    "            total_cost += cost\n",
    "\n",
    "        return total_cost \n",
    "\n",
    "  \n",
    "    # Makes of a plot of the observable data vs. predicted data for input parameters\n",
    "    def plot_comparison(self, dose=None, params=None, data=None):\n",
    "        if params is None:\n",
    "            params= self.p_true\n",
    "        if data is None:\n",
    "            data= self.data\n",
    "        res= self.run(params=params)\n",
    "        # Plot observables\n",
    "        for i,o in enumerate(self.observables):    \n",
    "            plt.plot(res[:,0],res[:,i+1]/res[0,i+1],label=o,color=colors[i])\n",
    "            plt.plot(data['time'].values, data[o].values,'o',color=colors[i]) # Removed division by self since already fold change data\n",
    "        cost= -self.log_likelihood(params)\n",
    "        plt.yscale('linear')\n",
    "        plt.title(f'cost:{cost:0.2e} {params}')\n",
    "        plt.xlabel('time (minutes)')\n",
    "        plt.ylabel('Fraction of molecules')\n",
    "        #_= plt.legend()\n",
    "        return()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from BNGL\n",
    "model_name=\"nfkb\"\n",
    "model = bng.bngmodel(model_name + \".bngl\")\n",
    "sim = model.setup_simulator() # sim is a libroadrunner simulator object\n",
    "\n",
    "# Extract model parameter names and values\n",
    "# NOTE: Parameters ending with '0' are skipped to avoid fitting initial concentrations.\n",
    "\n",
    "# Fitting all parameters NOT including the initial conditions\n",
    "pnames=[]\n",
    "pvals=[]\n",
    "for p in model.parameters:\n",
    "    ## Skip internal BNG parameters\n",
    "    if re.match('_',p)!=None: continue\n",
    "    ## Skip initial concentration parameters. COMMENT OUT this line if you don't want these skipped\n",
    "    if re.search('0$',p)!=None: continue\n",
    "    ## Skip initial values of input parameters\n",
    "    if re.search('_input$',p)!=None: continue\n",
    "    pnames.append(p)\n",
    "    val= eval(model.parameters[p].value)\n",
    "    pvals.append(val)\n",
    "lb = [0.01*val for val in pvals] # Increased range for lower and upper bounds\n",
    "ub = [100*val for val in pvals]\n",
    "print(\"All parameters:\",pnames) \n",
    "print(pvals)\n",
    "print(f'{lb}')\n",
    "print(f'{ub}')\n",
    "\n",
    "# set up Model object for more advanced tasks\n",
    "mod_opts = {} #creates a dictionary    \n",
    "mod_opts['observables'] = ['STATp'] # this is the observable in model, must divide by initial value\n",
    "mod_opts['rr'] = sim\n",
    "mod_opts['params'] = pnames #\n",
    "mod_opts['p_true'] = np.array(pvals) \n",
    "mod_opts['lower_bnds'] = lb #lower bounds\n",
    "mod_opts['upper_bnds'] = ub #upper bounds\n",
    "mod_opts['times']= np.linspace(0,100,101)#np.array([0,5,10,20,30,45,60,90,120,180,240,300,360])\n",
    "model = Model(mod_opts)\n",
    "display(mod_opts['times'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SBML File: Done\n",
    "\n",
    "nfkb_sbml.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions Table: Done\n",
    "experimental_conditions.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial conditions\n",
    "exp_conds = {\n",
    "\n",
    "    # defines conditions \n",
    "    'conditionId': ['init_conds'],\n",
    "    # human readable description\n",
    "    'conditionName': ['initial conditions'],\n",
    "    # initial TNFR concentration\n",
    "    'TNFRin': [2.5257],\n",
    "    # initial IKK concentration \n",
    "    'IKKin': [4.7454],\n",
    "    # intial cytoplasmic bound\n",
    "    'boundc': [6.5546]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change from dictonary to dataframe \n",
    "experimental_conditions = pd.DataFrame(exp_conds)\n",
    "\n",
    "## change from dataframe to .tsv file \n",
    "experimental_conditions.to_csv('experimental_conditions.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observable Table: Done\n",
    "\n",
    "observables.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = {\n",
    "\n",
    "#     # name of observables to link to the measurements\n",
    "#     'observableId': ['TNF', 'TNFRi', 'TNFRa', 'IKKi', 'IKKa', 'cNFkB', 'nNFkB', 'cIkB', 'nIkB', 'cNFkB_IkB', 'nNFkB_IkB', 'A20'],\n",
    "#     # human readable description of the observables\n",
    "#     'observableName': ['TNF', 'TNFR(st~i)', 'TNFR(st~a)', 'IKK(s~I)', 'IKK(s~A)', 'NFkB(IkB,loc~c)', 'NFkB(IkB,loc~n)', 'IkB(NFkB,loc~c)', 'IkB(NFkB,loc~n)', 'NFkB(IkB!0,loc~c).IkB(NFkB!0,loc~c)', 'NFkB(IkB!0,loc~n).IkB(NFkB!0,loc~n)', 'A20'],\n",
    "#     # mathematical formula for how the model output is calculated \n",
    "#     'observableFormula': ['TNF', 'TNFR(st~i)', 'TNFR(st~a)', 'IKK(s~I)', 'IKK(s~A)', 'NFkB(IkB,loc~c)', 'NFkB(IkB,loc~n)', 'IkB(NFkB,loc~c)', 'IkB(NFkB,loc~n)', 'NFkB(IkB!0,loc~c).IkB(NFkB!0,loc~c)', 'NFkB(IkB!0,loc~n).IkB(NFkB!0,loc~n)', 'A20']\n",
    "#     ## can specify a noise formula and noise distribution\n",
    "#     # 'noiseFormula': [],\n",
    "#     # 'noiseDistribution': []\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = {\n",
    "    'observableId': ['TNF_obs', 'TNFRi_obs', 'TNFRa_obs', 'IKKi_obs', 'IKKa_obs', 'cNFkB_obs', 'nNFkB_obs', 'cIkB_obs', 'nIkB_obs', 'cNFkB_IkB_obs', 'nNFkB_IkB_obs', 'A20_obs'],\n",
    "    'observableName': ['TNF', 'TNFR(st~i)', 'TNFR(st~a)', 'IKK(s~I)', 'IKK(s~A)', 'NFkB(IkB,loc~c)', 'NFkB(IkB,loc~n)', 'IkB(NFkB,loc~c)', 'IkB(NFkB,loc~n)', 'NFkB(IkB!0,loc~c).IkB(NFkB!0,loc~c)', 'NFkB(IkB!0,loc~n).IkB(NFkB!0,loc~n)', 'A20'],\n",
    "    'observableFormula': ['TNF', 'TNFR_st_i', 'TNFR_st_a', 'IKK_s_I', 'IKK_s_A', 'NFkB_IkB_loc_c', 'NFkB_IkB_loc_n', 'IkB_NFkB_loc_c', 'IkB_NFkB_loc_n', 'NFkB_IkB_0_loc_c_IkB_NFkB_0_loc_c', 'NFkB_IkB_0_loc_n_IkB_NFkB_0_loc_n', 'A20'],\n",
    "    'noiseFormula': ['0.01 * TNF', '0.01 * TNFR_st_i', '0.01 * TNFR_st_a', '0.01 * IKK_s_I', '0.01 * IKK_s_A', '0.01 * NFkB_IkB_loc_c', '0.01 * NFkB_IkB_loc_n', '0.01 * IkB_NFkB_loc_c', '0.01 * IkB_NFkB_loc_n', '0.01 * NFkB_IkB_0_loc_c_IkB_NFkB_0_loc_c', '0.01 * NFkB_IkB_0_loc_n_IkB_NFkB_0_loc_n', '0.01 * A20']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change from dictonary to dataframe \n",
    "observables = pd.DataFrame(obs)\n",
    "\n",
    "## change from dataframe to .tsv file \n",
    "observables.to_csv('observables.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement Table: Done\n",
    "\n",
    "measurement_data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import .csv file with the data\n",
    "\n",
    "nfkb_data = pd.read_csv('NFkB_sim_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename nNfkB column to measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfkb_data = nfkb_data.rename(columns={'nNFkB': 'measurement'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfkb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_info = {\n",
    "\n",
    "    # references the observable ID from observable file\n",
    "    'observableId': ['nNFkB'],\n",
    "    # references condition ID from the experimental condition file \n",
    "    'simulationConditionId': ['init_conds']\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn that into a df where they each get repeated 300 times \n",
    "\n",
    "nfkb = pd.DataFrame({key: value * 301 for key, value in measurement_info.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfkb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge nfkb and nfkb_data\n",
    "\n",
    "measurements = [nfkb, nfkb_data]\n",
    "measurements\n",
    "\n",
    "measurement_data = pd.concat(measurements, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn it into a .tsv file\n",
    "## change from dataframe to .tsv file \n",
    "measurement_data.to_csv('measurement_data.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Table: Done\n",
    "\n",
    "parameters.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\n",
    "    # parameter name as defined in sbml\n",
    "    'parameterId': ['k_b', 'k_f', 'k_a', 'k_4', 'k_i1', 'k_e1', 'k_t2a', 'k_t1a', 'k_i2', 'k_e2', 'k_e2a', 'c_4a', 'c_5a', 'c_1a', 'k_a1a', 'k_d1a', 'c_3', 'c_1', 'k_ikk', 'k_tnfr', 'TNFRin', 'IKKin', 'boundc'],\n",
    "    # log10 (better for estimation) or lin (if the parameters can be negative)\n",
    "    'parameterScale': ['log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10'],\n",
    "    # bounds \n",
    "    'lowerBound': [1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5, 1E-5],\n",
    "    'upperBound': [1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5, 1E+5],\n",
    "    # known values: keep empty if there are none\n",
    "    'nominalValue': ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
    "    # define if parameters are estimated\n",
    "    ## 1: estimate\n",
    "    ## 0: fixed to nominalValue\n",
    "    'estimate': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change from dictonary to dataframe \n",
    "parameters = pd.DataFrame(params)\n",
    "\n",
    "## change from dataframe to .tsv file \n",
    "parameters.to_csv('parameters.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Table: \n",
    "\n",
    "visualization_specifications.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = {\n",
    "\n",
    "    # specifies plots: all lines with same plot ID combined into 1 plot\n",
    "    'plotId': ['plot1'],\n",
    "    # plotting style of measurement data\n",
    "    'plotTypeData': ['Mean'],\n",
    "    # label for x axis \n",
    "    'xLabel': ['Time'],\n",
    "    # defines what is plotted \n",
    "    'yValues': ['nNFkB'],\n",
    "    # label for y axis\n",
    "    'yLabel': ['nNFkB Conentration']\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change from dictonary to dataframe \n",
    "visualization_specifications = pd.DataFrame(viz)\n",
    "\n",
    "## change from dataframe to .tsv file \n",
    "visualization_specifications.to_csv('visualization_specifications.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "params",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
